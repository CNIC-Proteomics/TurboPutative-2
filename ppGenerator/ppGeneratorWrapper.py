#!/usr/bin/env python

# -*- coding: utf-8 -*-

'''
Name: Rafael Barrero Rodriguez
Date: 2021-04-22
Description: Script para generar base de datos que relaciona nombre inicial con nombre
final.
Execution: python ppGenerator\ppGeneratorWrapper.py
'''

#
# Import modules
#
import os
import sys
import subprocess
import pandas as pd
import numpy as np

import time; start_time = time.time(); getTime = lambda : round(time.time() - start_time,3)

#
# Constants
#
scriptPath = os.path.dirname(__file__)
processedCompoundsFile = "pre_processed_compound.txt"

characterToReplace = {
    '±': '+/-',
    'α': 'alpha',
    'β': 'beta',
    'γ': 'gamma',
    'δ': 'delta',
    'ω': 'omega'
}

#
# Parameters
#
workDirPath = scriptPath # Path to working directory (in principle, script path)
inFile = "compoundList.xlsx" # File with the list of compounds

destinyFilePath = r"D:\CNIC\Metabolomica\TurboPutative-2.0\TPProcesser\REname\data\preProcessedNames.tsv"
destinyIndexPath = r"D:\CNIC\Metabolomica\TurboPutative-2.0\TPProcesser\REname\data\preProcessedNamesIndex.tsv"

if __name__ == "__main__":

    print(f"** {getTime()}s - Start processing")

    inFilePath = os.path.join(workDirPath, inFile)

    # Preprocess name of the compounds emulating PreProcesser
    preProcessedFile = "compoundList.txt"

    df = pd.read_excel(inFilePath, header=None, engine="openpyxl") 
    df.rename(columns={0:'name'}, inplace=True)

    df['name'] = df['name'].str.replace(r"(;|\s/\s|\n)(\n|.)*$", "", regex=True)  # Remove multiple compounds in a single field
    
    for i in characterToReplace:
        df['name'] = df['name'].str.replace(i, characterToReplace[i])

    df['name'] = df['name'].str.strip() # strip names of the compounds

    df.to_csv(os.path.join(workDirPath, preProcessedFile), header=None, index=None, sep="\t")  

    # Execute first part of name processing
    print(f"** {getTime()}s - Execute ppGenerator1.exe")
    dbGenerator1Path = os.path.join(scriptPath, "ppGenerator1.exe")
    subprocess.run([dbGenerator1Path, workDirPath, preProcessedFile], shell=True, check=True)

    # Execute TPGoslin
    print(f"** {getTime()}s - Execute TPGoslin.exe")
    TPGoslinPath = r"D:\CNIC\Metabolomica\TurboPutative-2.0\TPProcesser\REname\lib\cppgoslin-1.1.2\TPGoslin.exe"
    subprocess.run([TPGoslinPath, workDirPath], shell=True, check=True)

    # Execute second part of name processing
    print(f"** {getTime()}s - Execute ppGenerator2.exe")
    dbGenerator2Path = os.path.join(scriptPath, "ppGenerator2.exe")
    subprocess.run([dbGenerator2Path, workDirPath], shell=True, check=True)

    # Read .tsv with initial and final names
    print(f"** {getTime()}s - Reading original compounds")
    originalCompounds = pd.read_csv(os.path.join(workDirPath, preProcessedFile), sep="\t", header=None)
    originalCompounds.rename(columns={0:'original'}, inplace=True)
    originalCompounds['original'] = originalCompounds['original'].str.lower()

    print(f"** {getTime()}s - Reading preProcessed compounds")
    processedCompounds = pd.read_csv(os.path.join(workDirPath, processedCompoundsFile), sep="\t", header=None)
    processedCompounds.rename(columns={0:'preProcessed'}, inplace=True)

    print(f"** {getTime()}s - Build map table")
    mapTable = pd.concat([originalCompounds, processedCompounds], axis=1)

    # Read destiny file
    print(f"** {getTime()}s - Read old map table")
    mapTableOld = pd.read_csv(destinyFilePath, sep="\t", header=None)
    mapTableOld.rename(columns={0:'original', 1:'preProcessed'}, inplace=True)

    # Combine both .tsv and remove repetitions
    print(f"** {getTime()}s - Update map table")
    mapTableUpdated = pd.concat([mapTable, mapTableOld])
    mapTableUpdated.drop_duplicates(subset='original', inplace=True)
    mapTableUpdated.sort_values(by=['original'], inplace=True)

    # Save map table
    print(f"** {getTime()}s - Writing map table")
    mapTableUpdated.to_csv(destinyFilePath, sep="\t", header=None, index=None)

    # Build index
    print(f"** {getTime()}s - Building index")
    originalArr = mapTableUpdated.iloc[:, 0].to_numpy()
    lenIdx = int(np.sqrt(len(originalArr)))

    index = [[i, n] for n,i in enumerate(originalArr) if n%lenIdx==0]
    indexTable = pd.DataFrame(index)
    indexTable.to_csv(destinyIndexPath, header=None, index=None, sep="\t")

    # Remove intermediate files
    os.remove(os.path.join(workDirPath, preProcessedFile)) # File with original compounds but with first pre processing
    os.remove(os.path.join(workDirPath, "compound.txt")) # File generated by ppGenerator1.exe with compounds that will be processed by TPGoslin
    os.remove(os.path.join(workDirPath, "parsed_compound.txt")) # File generated by TPGoslin.exe with processed compounds
    os.remove(os.path.join(workDirPath, "compound_original.txt")) # File with compounds processed by ppGenerator.exe
    os.remove(os.path.join(workDirPath, "compound_index.txt")) # File with index of compounds
    os.remove(os.path.join(workDirPath, processedCompoundsFile)) # File with processed compounds generated by ppGenerator2.exe